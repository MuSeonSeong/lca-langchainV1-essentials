{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "483ab18e-f419-46ad-9bbe-171ffd05f983",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "Streaming...\n",
    "\n",
    "There are two types frequently used with Agents:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166fc0b1-2322-4dd2-a358-89309fb9f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "from langchain_core.tools import tool\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a26b4586-453a-4c10-9fae-4be3f4cb6cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = init_chat_model(\"gpt-5-mini\", model_provider=\"openai\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=model,\n",
    "    tools=[],\n",
    "    prompt=SystemMessage(content=\"You are a full-stack comedian\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a907aa9-a608-47e2-92d4-6758a1728cb2",
   "metadata": {},
   "source": [
    "## No Steaming (invoke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc384cf0-b208-4ab1-b7e2-f4b93dab08bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the full-stack developer go broke?\n",
      "\n",
      "Because he used up all his cache.\n",
      "\n",
      "Want another one?\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \n",
    "                   \"content\": \"Tell me a joke\"}]}\n",
    "    )\n",
    "print(result[\"messages\"][1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4d7975-8d94-4d5e-8493-e68ac9fcedf9",
   "metadata": {},
   "source": [
    "## value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e30a2273-1dd3-47e8-a38e-05ed4b750000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Tell me a joke\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I’d tell you a UDP joke, but I’m not sure you’d get it.\n",
      "\n",
      "Want another—TCP, HTTP, or something non-tech?\n"
     ]
    }
   ],
   "source": [
    "# Stream = values\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \n",
    "                   \"content\": \"Tell me a joke\"}]},\n",
    "    stream_mode=\"values\",\n",
    "    ):\n",
    "    step[\"messages\"][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada88835-3c66-4241-b3d9-4f3d38390c86",
   "metadata": {},
   "source": [
    "## message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1c07c50-7b96-4446-9065-0733e1b0b308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node: agent\n",
      "content: \n",
      "node: agent\n",
      "content: Why\n",
      "node: agent\n",
      "content:  did\n",
      "node: agent\n",
      "content:  the\n",
      "node: agent\n",
      "content:  web\n",
      "node: agent\n",
      "content:  developer\n",
      "node: agent\n",
      "content:  go\n",
      "node: agent\n",
      "content:  broke\n",
      "node: agent\n",
      "content: ?\n",
      "node: agent\n",
      "content:  Because\n",
      "node: agent\n",
      "content:  he\n",
      "node: agent\n",
      "content:  used\n",
      "node: agent\n",
      "content:  up\n",
      "node: agent\n",
      "content:  all\n",
      "node: agent\n",
      "content:  his\n",
      "node: agent\n",
      "content:  cache\n",
      "node: agent\n",
      "content: .\n",
      "node: agent\n",
      "content: \n"
     ]
    }
   ],
   "source": [
    "for token, metadata in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke.\"}]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    print(f\"node: {metadata['langgraph_node']}\")\n",
    "    print(f\"content: {token.content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a9cc553-7357-4d36-b88d-25eaf7462cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The server hums a low applause, the browser blushes blue,\n",
      "I stand between the markup and the midnight, telling jokes to you.\n",
      "CSS fluffs up its ruffles; JavaScript trips on a grin —\n",
      "I deploy a punchline, hit refresh, and watch the laughter spin.\n",
      "\n",
      "My backend keeps the secrets, polite and tightly spun,\n",
      "SQLs whisper algorithms, telling puns in rows of one.\n",
      "The cache remembers yesterday’s best bits and then forgets,\n",
      "So I git-commit a new riff — wild, imperfect, yet.\n",
      "\n",
      "A merge conflict in the chorus, a race condition in the rhyme,\n",
      "I catch exceptions with a wink and log the memory of time.\n",
      "The stack trace is my set list, each line a tiny spark,\n",
      "From localhost to starlight, from studio to dark.\n",
      "\n",
      "Listeners are sockets open, awaiting something kind —\n",
      "A bit of warm absurdity to loosen up the mind.\n",
      "I debug subtle sorrows with a well-timed little gag,\n",
      "And patch the holes with laughter, one soft semicolon tag.\n",
      "\n",
      "So here’s my deploy: a poem, full-stack and slightly wrong,\n",
      "Built with coffee, odd optimism, and half a marching song.\n",
      "If it crashes, laugh; if it compiles, pass the popcorn, friend —\n",
      "In the end we’re all just processes that hope the chorus never ends."
     ]
    }
   ],
   "source": [
    "for token, metadata in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Write me a poem.\"}]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    print(f\"{token.content}\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c4477-24ff-4321-8f50-aff3324fa831",
   "metadata": {},
   "source": [
    "## Tools can stream too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c68179e6-d388-494a-b10d-109c230f6ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('updates', {'agent': {'messages': [AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 218, 'prompt_tokens': 132, 'total_tokens': 350, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CNhIWNs9mupBpZkKs77237j5elaaI', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--5e224b37-a175-4908-bf88-cc625789e6a1-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco, CA'}, 'id': 'call_Doq6ytEN8PooMN0KJx4Ln8u7', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 218, 'total_tokens': 350, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}})]}})\n",
      "('custom', 'Looking up data for city: San Francisco, CA')\n",
      "('custom', 'Acquired data for city: San Francisco, CA')\n",
      "('updates', {'tools': {'messages': [ToolMessage(content=\"It's always sunny in San Francisco, CA!\", name='get_weather', tool_call_id='call_Doq6ytEN8PooMN0KJx4Ln8u7')]}})\n",
      "('updates', {'agent': {'messages': [AIMessage(content=\"It's always sunny in San Francisco, CA.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 172, 'total_tokens': 184, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CNhIcy0TD28JXNCAzoo3ljiiTqOKD', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--50402217-e471-4442-9c4a-ce8ad40e737d-0', usage_metadata={'input_tokens': 172, 'output_tokens': 12, 'total_tokens': 184, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})]}})\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.config import get_stream_writer\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    writer = get_stream_writer()\n",
    "    # stream any arbitrary data\n",
    "    writer(f\"Looking up data for city: {city}\")\n",
    "    writer(f\"Acquired data for city: {city}\")\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5-mini\",\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"updates\", \"custom\"]\n",
    "\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4d7ef47-e857-4e07-a233-888306e3e0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up data for city: San Francisco, CA\n",
      "Acquired data for city: San Francisco, CA\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"updates\", \"custom\"]\n",
    "\n",
    "):\n",
    "    if chunk[0] == \"custom\":\n",
    "        print(chunk[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072fb561-fc30-4095-bfc5-8a35809aa307",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
