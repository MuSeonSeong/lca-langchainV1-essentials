{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "483ab18e-f419-46ad-9bbe-171ffd05f983",
   "metadata": {},
   "source": [
    "# Streaming\n",
    "\n",
    "Streaming...\n",
    "\n",
    "There are two types frequently used with Agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "166fc0b1-2322-4dd2-a358-89309fb9f4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a26b4586-453a-4c10-9fae-4be3f4cb6cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5-mini\",\n",
    "    system_prompt=\"You are a full-stack comedian\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a907aa9-a608-47e2-92d4-6758a1728cb2",
   "metadata": {},
   "source": [
    "## No Steaming (invoke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc384cf0-b208-4ab1-b7e2-f4b93dab08bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the developer go broke? Because he used up all his cache.\n"
     ]
    }
   ],
   "source": [
    "result = agent.invoke({\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke\"}]})\n",
    "print(result[\"messages\"][1].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4d7975-8d94-4d5e-8493-e68ac9fcedf9",
   "metadata": {},
   "source": [
    "## values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e30a2273-1dd3-47e8-a38e-05ed4b750000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Tell me a joke\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Why do programmers prefer dark mode?\n",
      "\n",
      "Because light attracts bugs.\n",
      "\n",
      "Want another one—front-end, back-end, or full-stack roast?\n"
     ]
    }
   ],
   "source": [
    "# Stream = values\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Tell me a joke\"}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada88835-3c66-4241-b3d9-4f3d38390c86",
   "metadata": {},
   "source": [
    "## message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a9cc553-7357-4d36-b88d-25eaf7462cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I wrote you a poem in JavaScript,\n",
      "but it kept returning undefined,\n",
      "so I refactored it in coffee—black, no sugar—\n",
      "and the loop of longing finally broke.\n",
      "\n",
      "There’s a little server in my chest\n",
      "that listens on port midnight,\n",
      "accepts requests with a soft \"hello\" header,\n",
      "and responds with an emoji of your name.\n",
      "\n",
      "I commit small acts of kindness like pushes,\n",
      "and merge them into the main branch of days.\n",
      "Sometimes bugs slip through—missing silence,\n",
      "a race condition of busy schedules—but\n",
      "I write tests: I call, I knock, I show up.\n",
      "\n",
      "Your smile is a bugfix that compiles at sunrise,\n",
      "turns my deprecated fears into legacy comments.\n",
      "We deploy ourselves on messy afternoons,\n",
      "rolled back only when laughter demands it.\n",
      "\n",
      "If love had a stack trace it would point to you:\n",
      "line one, the breath you borrow from the air;\n",
      "line two, the coffee shared at half-past too-late;\n",
      "line three, the quiet where both our cursors blink.\n",
      "\n",
      "So here’s the README: I like you. I will update.\n",
      "No permission required, no sudo, just try it.\n",
      "If it times out, hit refresh. If it crashes, cuddle the logs.\n",
      "If it works, we’ll ship the next version together."
     ]
    }
   ],
   "source": [
    "for token, metadata in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"Write me a poem.\"}]},\n",
    "    stream_mode=\"messages\",\n",
    "):\n",
    "    print(f\"{token.content}\", end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d47c4477-24ff-4321-8f50-aff3324fa831",
   "metadata": {},
   "source": [
    "## Tools can stream too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c68179e6-d388-494a-b10d-109c230f6ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='fae1ef24-aed9-4e7f-8f5e-cf053497f728')]})\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='fae1ef24-aed9-4e7f-8f5e-cf053497f728'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 132, 'total_tokens': 222, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CO5C8M1sv5jIo1pawZTaQCrTnkxdT', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--58b5f6cd-416d-479d-9a55-2296963543a8-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco, CA'}, 'id': 'call_Hi0zOyZ9AK7ZS3hBBbyQ0xLJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 90, 'total_tokens': 222, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}})], 'thread_model_call_count': 1, 'run_model_call_count': 1})\n",
      "('custom', 'Looking up data for city: San Francisco, CA')\n",
      "('custom', 'Acquired data for city: San Francisco, CA')\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='fae1ef24-aed9-4e7f-8f5e-cf053497f728'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 132, 'total_tokens': 222, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CO5C8M1sv5jIo1pawZTaQCrTnkxdT', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--58b5f6cd-416d-479d-9a55-2296963543a8-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco, CA'}, 'id': 'call_Hi0zOyZ9AK7ZS3hBBbyQ0xLJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 90, 'total_tokens': 222, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}}), ToolMessage(content=\"It's always sunny in San Francisco, CA!\", name='get_weather', id='ed295085-49b9-47c6-bf59-e9503da5de8c', tool_call_id='call_Hi0zOyZ9AK7ZS3hBBbyQ0xLJ')], 'thread_model_call_count': 1, 'run_model_call_count': 1})\n",
      "('values', {'messages': [HumanMessage(content='What is the weather in SF?', additional_kwargs={}, response_metadata={}, id='fae1ef24-aed9-4e7f-8f5e-cf053497f728'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 90, 'prompt_tokens': 132, 'total_tokens': 222, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 64, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CO5C8M1sv5jIo1pawZTaQCrTnkxdT', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--58b5f6cd-416d-479d-9a55-2296963543a8-0', tool_calls=[{'name': 'get_weather', 'args': {'city': 'San Francisco, CA'}, 'id': 'call_Hi0zOyZ9AK7ZS3hBBbyQ0xLJ', 'type': 'tool_call'}], usage_metadata={'input_tokens': 132, 'output_tokens': 90, 'total_tokens': 222, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 64}}), ToolMessage(content=\"It's always sunny in San Francisco, CA!\", name='get_weather', id='ed295085-49b9-47c6-bf59-e9503da5de8c', tool_call_id='call_Hi0zOyZ9AK7ZS3hBBbyQ0xLJ'), AIMessage(content='The weather service returned: \"It\\'s always sunny in San Francisco, CA!\"\\n\\nWould you like more specific details (current temperature, wind, hourly forecast, or a 7-day outlook)?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 238, 'prompt_tokens': 172, 'total_tokens': 410, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 192, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-mini-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CO5CAhdrDR56R971YFLHuQ8IYbO48', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--3939232c-d4ab-4f3e-b798-9a1ba814bd46-0', usage_metadata={'input_tokens': 172, 'output_tokens': 238, 'total_tokens': 410, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 192}})], 'thread_model_call_count': 2, 'run_model_call_count': 2})\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langgraph.config import get_stream_writer\n",
    "\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get weather for a given city.\"\"\"\n",
    "    writer = get_stream_writer()\n",
    "    # stream any arbitrary data\n",
    "    writer(f\"Looking up data for city: {city}\")\n",
    "    writer(f\"Acquired data for city: {city}\")\n",
    "    return f\"It's always sunny in {city}!\"\n",
    "\n",
    "\n",
    "agent = create_agent(\n",
    "    model=\"openai:gpt-5-mini\",\n",
    "    tools=[get_weather],\n",
    ")\n",
    "\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"values\", \"custom\"],\n",
    "):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b4d7ef47-e857-4e07-a233-888306e3e0c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking up data for city: San Francisco, CA\n",
      "Acquired data for city: San Francisco, CA\n"
     ]
    }
   ],
   "source": [
    "for chunk in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": \"What is the weather in SF?\"}]},\n",
    "    stream_mode=[\"values\", \"custom\"],\n",
    "):\n",
    "    if chunk[0] == \"custom\":\n",
    "        print(chunk[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
