{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ba24dd6-7a31-4fba-8077-2bff96e1ed4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///Chinook.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f2474e1-6abf-4c24-bf50-b75090ec1ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import init_chat_model\n",
    "\n",
    "llm = init_chat_model(\"openai:gpt-5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d7f0b2c-200a-4246-b547-aff9b5185562",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "    \n",
    "@tool\n",
    "def execute_sql(query: str) -> str:\n",
    "    \"\"\"Execute a SQLite command and return results.\"\"\"\n",
    "    #query = _safe_sql(query)\n",
    "    q = query\n",
    "    if q.startswith(\"Error:\"):\n",
    "        return q\n",
    "    try:\n",
    "        return db.run(q)\n",
    "    except Exception as e:\n",
    "        return f\"Error: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29e1c020-db18-418a-8693-cb4ed21d4f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM = f\"\"\"You are a careful SQLite analyst.\n",
    "\n",
    "Rules:\n",
    "- Think step-by-step.\n",
    "- When you need data, call the tool `execute_sql` with ONE SELECT query.\n",
    "- Read-only only; no INSERT/UPDATE/DELETE/ALTER/DROP/CREATE/REPLACE/TRUNCATE.\n",
    "- Limit to 5 rows unless the user explicitly asks otherwise.\n",
    "- If the tool returns 'Error:', revise the SQL and try again.\n",
    "- Prefer explicit column lists; avoid SELECT *.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a26b4586-453a-4c10-9fae-4be3f4cb6cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "#llm = init_chat_model(\"claude-3-5-sonnet-latest\", model_provider=\"anthropic\")\n",
    "llm = init_chat_model(\"gpt-5\", model_provider=\"openai\")\n",
    "\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[execute_sql],\n",
    "    prompt=SystemMessage(content=SYSTEM),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e30a2273-1dd3-47e8-a38e-05ed4b750000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Which table has the largest number of entries?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  execute_sql (call_t2N4ZuQZg8vLSoeCaViLTNw0)\n",
      " Call ID: call_t2N4ZuQZg8vLSoeCaViLTNw0\n",
      "  Args:\n",
      "    query: SELECT group_concat(name, '|') AS tables FROM sqlite_master WHERE type = 'table' AND name NOT LIKE 'sqlite_%';\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: execute_sql\n",
      "\n",
      "[('Album|Artist|Customer|Employee|Genre|Invoice|InvoiceLine|MediaType|Playlist|PlaylistTrack|Track',)]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  execute_sql (call_rg9KlHcyTgTNUWJ4NVPw6YoW)\n",
      " Call ID: call_rg9KlHcyTgTNUWJ4NVPw6YoW\n",
      "  Args:\n",
      "    query: SELECT table_name, row_count FROM (\n",
      "  SELECT 'Album' AS table_name, COUNT(*) AS row_count FROM Album\n",
      "  UNION ALL\n",
      "  SELECT 'Artist' AS table_name, COUNT(*) AS row_count FROM Artist\n",
      "  UNION ALL\n",
      "  SELECT 'Customer' AS table_name, COUNT(*) AS row_count FROM Customer\n",
      "  UNION ALL\n",
      "  SELECT 'Employee' AS table_name, COUNT(*) AS row_count FROM Employee\n",
      "  UNION ALL\n",
      "  SELECT 'Genre' AS table_name, COUNT(*) AS row_count FROM Genre\n",
      "  UNION ALL\n",
      "  SELECT 'Invoice' AS table_name, COUNT(*) AS row_count FROM Invoice\n",
      "  UNION ALL\n",
      "  SELECT 'InvoiceLine' AS table_name, COUNT(*) AS row_count FROM InvoiceLine\n",
      "  UNION ALL\n",
      "  SELECT 'MediaType' AS table_name, COUNT(*) AS row_count FROM MediaType\n",
      "  UNION ALL\n",
      "  SELECT 'Playlist' AS table_name, COUNT(*) AS row_count FROM Playlist\n",
      "  UNION ALL\n",
      "  SELECT 'PlaylistTrack' AS table_name, COUNT(*) AS row_count FROM PlaylistTrack\n",
      "  UNION ALL\n",
      "  SELECT 'Track' AS table_name, COUNT(*) AS row_count FROM Track\n",
      ")\n",
      "ORDER BY row_count DESC\n",
      "LIMIT 1;\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: execute_sql\n",
      "\n",
      "[('PlaylistTrack', 8715)]\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "PlaylistTrack, with 8,715 rows.\n"
     ]
    }
   ],
   "source": [
    "question = \"Which table has the largest number of entries?\"\n",
    "\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "40daa5d2-1148-4075-b91a-52fb443deca7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'messages': [HumanMessage(content='Which genre on average has the longest tracks?', additional_kwargs={}, response_metadata={}, id='6195ebbb-476e-40ba-bef1-3f14fb55b6a9'), AIMessage(content='', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 414, 'prompt_tokens': 233, 'total_tokens': 647, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 320, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLv2NObD9MJdGcPuyZL3NdV17SK9U', 'service_tier': 'default', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--7eef351d-24ed-4af7-b5a2-cf00da3083ac-0', tool_calls=[{'name': 'execute_sql', 'args': {'query': 'SELECT g.Name AS Genre, AVG(t.Milliseconds) AS avg_ms, ROUND(AVG(t.Milliseconds)/60000.0, 2) AS avg_minutes\\nFROM Track t\\nJOIN Genre g ON t.GenreId = g.GenreId\\nGROUP BY g.GenreId, g.Name\\nORDER BY avg_ms DESC\\nLIMIT 1;'}, 'id': 'call_IbNlMNp15rkcXKypPznfOLnb', 'type': 'tool_call'}], usage_metadata={'input_tokens': 233, 'output_tokens': 414, 'total_tokens': 647, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 320}}), ToolMessage(content=\"[('Sci Fi & Fantasy', 2911783.0384615385, 48.53)]\", name='execute_sql', id='6bcb2197-66f2-4cb9-b90f-b9a556922379', tool_call_id='call_IbNlMNp15rkcXKypPznfOLnb'), AIMessage(content='Sci Fi & Fantasy â€” averaging about 48.53 minutes per track.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 280, 'prompt_tokens': 354, 'total_tokens': 634, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 256, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_provider': 'openai', 'model_name': 'gpt-5-2025-08-07', 'system_fingerprint': None, 'id': 'chatcmpl-CLv2TBBaHoeN7GLZZGlUupNW6STX3', 'service_tier': 'default', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--e712f9ca-8c44-4a7a-8552-6c953d751c19-0', usage_metadata={'input_tokens': 354, 'output_tokens': 280, 'total_tokens': 634, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 256}})]}\n"
     ]
    }
   ],
   "source": [
    "question = \"Which genre on average has the longest tracks?\"\n",
    "\n",
    "print( agent.invoke(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
    "    stream_mode=\"values\",\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7797b8f4-3d52-405c-a16e-baa2a71127df",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which genre on average has the longest tracks?\"\n",
    "\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a48e3902-d3d6-49a0-8f60-b8ba3d1f7400",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What are all the tables?\"\n",
    "\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b925b3-41b8-4d85-be32-e3a1b8557365",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"Which ones start with 'a'?\"\n",
    "\n",
    "for step in agent.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": question}]},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a25714c-d71e-4331-a731-519f9cb95d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, SystemMessage, HumanMessage\n",
    "\n",
    "# Create an AI message manually (e.g., for conversation history)\n",
    "ai_msg = AIMessage(\"I'd be happy to help you with that question!\")\n",
    "\n",
    "# Add to conversation history\n",
    "messages = [\n",
    "    SystemMessage(\"You are a helpful assistant\"),\n",
    "    HumanMessage(\"Can you help me?\"),\n",
    "    ai_msg,  # Insert as if it came from the model\n",
    "    HumanMessage(\"Great! What's 2+2?\")\n",
    "]\n",
    "\n",
    "#response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "612edc91-3d2c-4dc5-9555-0729e02cd796",
   "metadata": {},
   "outputs": [],
   "source": [
    "fagent = create_agent(\n",
    "    model=llm,\n",
    "    tools=[execute_sql],\n",
    "    prompt=SystemMessage(\"You are a helpful\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0ec4699-37ad-4d21-8daf-4ce8de375ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Great! What's 2+2?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for step in fagent.stream(\n",
    "    {\"messages\": messages},\n",
    "    stream_mode=\"values\",\n",
    "):\n",
    "    step[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9cc553-7357-4d36-b88d-25eaf7462cf6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
