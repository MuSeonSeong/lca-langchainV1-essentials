{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e80733f2",
   "metadata": {},
   "source": [
    "# Structured Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c8b0c9",
   "metadata": {},
   "source": [
    "Let's extract structured information from a messy conversation transcript. We'll define a `ContactInfo` schema and have the agent parse out the name, email, and phone number automatically. As this agent is using GPT-5 it automatically uses supported model capabilities for structured output extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3342fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import * as dotenv from \"dotenv/config\";\n",
    "import { z } from \"zod\";\n",
    "import { createAgent } from \"langchain\";\n",
    "\n",
    "const ContactInfo = z.object({\n",
    "    name: z.string(),\n",
    "    email: z.string(),\n",
    "    phone: z.string()\n",
    "});\n",
    "\n",
    "const agent = createAgent({\n",
    "    model: \"openai:gpt-5-mini\",\n",
    "    tools: [],\n",
    "    responseFormat: ContactInfo\n",
    "});\n",
    "\n",
    "const recordedConversation = `We talked with John Doe. He works over at Example. His number is, let's see, \n",
    "five, five, five, one two three, four, five, six seven. Did you get that?\n",
    "And, his email was john at example.com. He wanted to order 50 boxes of Captain Crunch.`\n",
    "\n",
    "const result = await agent.invoke({\n",
    "    \"messages\": [recordedConversation]\n",
    "})\n",
    "\n",
    "console.log(result.structuredResponse);\n",
    "console.log(result.messages);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68178d2",
   "metadata": {},
   "source": [
    "## Native vs. Tool Calling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c84e3cd",
   "metadata": {},
   "source": [
    "There are two ways to get structured output: using the model's native JSON mode (`providerStrategy`) or via tool calling (`toolStrategy`). Tool calling is more robust across different models, while native mode is faster when supported. Let's use `toolStrategy` to see the difference in the message flow.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14892cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import \"dotenv/config\";\n",
    "import { z } from \"zod\";\n",
    "import { createAgent, toolStrategy, providerStrategy } from \"langchain\";\n",
    "\n",
    "const ContactInfo = z.object({\n",
    "    name: z.string(),\n",
    "    email: z.string(),\n",
    "    phone: z.string()\n",
    "});\n",
    "\n",
    "const agent = createAgent({\n",
    "    model: \"openai:gpt-5-mini\",\n",
    "    tools: [],\n",
    "    // or providerStrategy(ContactInfo)\n",
    "    responseFormat: toolStrategy(ContactInfo)\n",
    "});\n",
    "\n",
    "const recordedConversation = `We talked with John Doe. He works over at Example. His number is, let's see, \n",
    "five, five, five, one two three, four, five, six seven. Did you get that?\n",
    "And, his email was john at example.com. He wanted to order 50 boxes of Captain Crunch.`\n",
    "\n",
    "const result = await agent.invoke({\n",
    "    \"messages\": [recordedConversation]\n",
    "})\n",
    "\n",
    "console.log(result.structuredResponse);\n",
    "console.log(result.messages);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
